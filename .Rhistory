perform.split <- function(data){
x     <- data[,1:d]
y     <- data[,d+1]
if( class(x) == 'numeric') {return( list(data) )}
axis  <- find.axis(data)
split <- find.split(x[,axis],y)
x1    <- x[x[,axis] <  split, ]
x2    <- x[x[,axis] >= split, ]
if( class(x1) == 'numeric'){ d1 = t(as.matrix( c(x1, y[x[,axis] <  split ]))) } else {
d1 = cbind( x1 , y[x[,axis] <  split ] ) }
if( class(x2) == 'numeric'){ d2 = t(as.matrix( c(x2, y[x[,axis] >= split ]))) } else {
d2 = cbind( x2 , y[x[,axis] >= split ] ) }
if( dim(d1)[1] == 0 ) {return(list(d2))}
if( dim(d2)[1] == 0 ) {return(list(d1))} else{
return(list(d1,d2, axis_split = c(axis,split)))
}
}
misclass.rest <- function(split_data,i){
sum ( sapply((1:(length(split_data) -1) )[-i], FUN = function(x) { y <- split_data[[x]][,d+1]; return(min( sum(y) , length(y) - sum(y)))}) )
}
misclass.own <- function(split_data, i){
split <- perform.split(split_data[[i]])
if(length(split)==1){
return(   min(sum (split[[1]][,d+1]),
dim(split[[1]])[1] - sum( split[[1]][,d+1] ) )
)
}
misclass <- min( sum ( split[[1]][,d+1] ) + dim(split[[2]])[1] - sum( split[[2]][,d+1] ),
sum ( split[[2]][,d+1] ) + dim(split[[1]])[1] - sum( split[[1]][,d+1] )
)
return(misclass)
}
partition <- function(split_data){
i <- which.min( sapply(1:(length(split_data)-1), FUN = function(x) { misclass.own(split_data, x) + misclass.rest(split_data, x) } ) )
data <- perform.split(split_data[[i]])
if( length(data) == 1){ return(split_data)}
axis_split <- rbind(split_data$axis_split, data$axis_split)
split_data[[i]]   <- NULL
split_data$axis_split <- NULL
n                 <- length(split_data)
split_data[[n+1]] <- data[[1]]
split_data[[n+2]] <- data[[2]]
split_data$axis_split <- axis_split
return(split_data)
}
decision.tree.build <- function(data, max_splits){
split_data <- perform.split(data)
if(max_splits==1){return(split_data)}
for(i in 2:max_splits){
if (length(partition(split_data)) == length(split_data)){return(split_data)}
split_data = partition(split_data)
}
return(split_data)
}
n=100
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
x <- data[,1:d]
y <- data[,d+1]
split_data <- perform.split(data)
split_data <- partition(split_data)
tree = decision.tree.build(data, max_splits = 10000)
tree
install.packages('data.tree')
install.packages('part')
install.packages('party')
rm(list=ls())
library(ggplot2)
library(dplyr)
library(plyr)
X.gen <- function(y,d){
if(y==0){
return(rnorm(d,0,1))
}
if(d <= 2){return(rnorm(d,1,1))}
return(c(rnorm(2,1,1), rnorm((d-2),0,1)))
}
xy.gen <- function(n,d){
Y <- rbinom(n,1,0.5)
X <- sapply(Y, FUN = function(x){X.gen(x,d)})
return(t(rbind(X,Y)))
}
n=100
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
misclassified <- function(x,y,split){
ind1 <- which(x>split)
ind2 <- which(x<=split)
misclass1 <- (length(ind1) - sum(y[ind1])) + sum(y[ind2])
return(min(misclass1, n - misclass1))
}
find.split <- function(x,y){
split = seq(min(x) - 0.001 ,max(x) + 0.001,length.out = 100)
misclass1 <- sapply(split, FUN = function(z) {misclassified(x,y,z)})
return(split[which.min(misclass1)])
}
find.axis <- function(data){
x     <- data[,1:d]
y     <- data[,d+1]
misclass <- apply(x,2,FUN = function(z){misclassified(z,y,find.split(z,y))})
return(which.min(misclass))
}
perform.split <- function(data){
x     <- data[,1:d]
y     <- data[,d+1]
if( class(x) == 'numeric') {return( list(data) )}
axis  <- find.axis(data)
split <- find.split(x[,axis],y)
x1    <- x[x[,axis] <  split, ]
x2    <- x[x[,axis] >= split, ]
if( class(x1) == 'numeric'){ d1 = t(as.matrix( c(x1, y[x[,axis] <  split ]))) } else {
d1 = cbind( x1 , y[x[,axis] <  split ] ) }
if( class(x2) == 'numeric'){ d2 = t(as.matrix( c(x2, y[x[,axis] >= split ]))) } else {
d2 = cbind( x2 , y[x[,axis] >= split ] ) }
if( dim(d1)[1] == 0 ) {return(list(d2))}
if( dim(d2)[1] == 0 ) {return(list(d1))} else{
return(list(d1,d2, axis_split = c(axis,split)))
}
}
misclass.rest <- function(split_data,i){
sum ( sapply((1:(length(split_data) -1) )[-i], FUN = function(x) { y <- split_data[[x]][,d+1]; return(min( sum(y) , length(y) - sum(y)))}) )
}
misclass.own <- function(split_data, i){
split <- perform.split(split_data[[i]])
if(length(split)==1){
return(   min(sum (split[[1]][,d+1]),
dim(split[[1]])[1] - sum( split[[1]][,d+1] ) )
)
}
misclass <- min( sum ( split[[1]][,d+1] ) + dim(split[[2]])[1] - sum( split[[2]][,d+1] ),
sum ( split[[2]][,d+1] ) + dim(split[[1]])[1] - sum( split[[1]][,d+1] )
)
return(misclass)
}
partition <- function(split_data){
i <- which.min( sapply(1:(length(split_data)-1), FUN = function(x) { misclass.own(split_data, x) + misclass.rest(split_data, x) } ) )
data <- perform.split(split_data[[i]])
if( length(data) == 1){ return(split_data)}
axis_split <- rbind(split_data$axis_split, data$axis_split)
split_data[[i]]   <- NULL
split_data$axis_split <- NULL
n                 <- length(split_data)
split_data[[n+1]] <- data[[1]]
split_data[[n+2]] <- data[[2]]
split_data$axis_split <- axis_split
return(split_data)
}
decision.tree.build <- function(data, max_splits){
split_data <- perform.split(data)
if(max_splits==1){return(split_data)}
for(i in 2:max_splits){
if (length(partition(split_data)) == length(split_data)){return(split_data)}
split_data = partition(split_data)
}
return(split_data)
}
n=100
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
x <- data[,1:d]
y <- data[,d+1]
split_data <- perform.split(data)
split_data <- partition(split_data)
tree = decision.tree.build(data, max_splits = 10000)
tree
i <- which.min( sapply(1:(length(split_data)-1), FUN = function(x) { misclass.own(split_data, x) + misclass.rest(split_data, x) } ) )
data <- perform.split(split_data[[i]])
if( length(data) == 1){ return(split_data)}
axis_split <- rbind(split_data$axis_split, data$axis_split)
split_data[[i]]   <- NULL
n                 <- length(split_data)
partition.tree <- function(split_data){
i <- which.min( sapply(1:(length(split_data)-1), FUN = function(x) { misclass.own(split_data, x) + misclass.rest(split_data, x) } ) )
data <- perform.split(split_data[[i]])
if( length(data) == 1){ return(split_data)}
split_data[[i]]   <- NULL
n                 <- length(split_data)
split_data[[n+1]] <- data
return(split_data)
}
n=10
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
x <- data[,1:d]
y <- data[,d+1]
split_data <- perform.split(data)
split_data <- partition.tree(split_data)
split_data
split_data <- partition.tree(split_data)
split_data
partition.tree <- function(split_data){
i <- which.min( sapply(1:(length(split_data)-1), FUN = function(x) { misclass.own(split_data, x) + misclass.rest(split_data, x) } ) )
data <- perform.split(split_data[[i]])
if( length(data) == 1){ return(split_data)}
split_data[[i]]   <- NULL
n                 <- length(split_data)
split_data[[n+1]] <- data
return(split_data)
}
n=10
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
x <- data[,1:d]
y <- data[,d+1]
split_data <- perform.split(data)
split_data <- partition.tree(split_data)
split_data
n=15
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
x <- data[,1:d]
y <- data[,d+1]
split_data <- perform.split(data)
split_data <- partition.tree(split_data)
split_data
split_data[[1]]
length( split_data[[1]] )
length( split_data[[1]] )
class( split_data[[1]] )
if(class(split_data[[x]]) == 'matrix'){}
if(class(split_data[[1]]) == 'matrix'){}
class(split_data[[1]]) == 'matrix'
class( split_data[[1]] )
split_data <- perform.split(data)
split_data <- partition.tree(split_data)
split_data <- partition.tree(split_data)
n=10
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
rm(list=ls())
library(ggplot2)
library(dplyr)
library(plyr)
X.gen <- function(y,d){
if(y==0){
return(rnorm(d,0,1))
}
if(d <= 2){return(rnorm(d,1,1))}
return(c(rnorm(2,1,1), rnorm((d-2),0,1)))
}
xy.gen <- function(n,d){
Y <- rbinom(n,1,0.5)
X <- sapply(Y, FUN = function(x){X.gen(x,d)})
return(t(rbind(X,Y)))
}
n=15
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
x <- data[,1:d]
y <- data[,d+1]
library(party)
help(cpart)
help(cpart())
help(party::cpart)
ctree(y ~ x)
n=15
d=3
data <- xy.gen(n,d)
colnames(data) <- c(seq(1,d),'Y')
x <- data[,1:d]
y <- data[,d+1]
ctree(Y ~ . , data = data )
data <- as.data.frame(data)
ctree(Y ~ . , data = data )
tree <- ctree(Y ~ . , data = data )
tree
plot(tree)
n = 3
2(n**2 + n) >= 2**(n+1) - 4
n = 3
2*(n**2 + n) >= 2**(n+1) - 4
2*(n**2 + n) <= 2**(n+1) - 4
n = 4
2*(n**2 + n) <= 2**(n+1) - 4
n = 6
2*(n**2 + n) <= 2**(n+1) - 4
5*log(50)
5*( log(50) - log(40)) - 4.96
5*( log(50) - log(40)) - 4.96*0.25
rm(list=ls())
setwd('/home/euan/documents/financial-econ/financial-econometrics-project/')
source('aparch.R')
dyn.load("APARCH.so")
data  <- read.csv('../data/tickers/DBB.csv')
data  <- data[seq(nrow(data),1,-1),]
price <- data$Adj.Close
x     <- ( log(price[2:length(price)]) - log(price[1:(length(price)-1)]) ) * 100
aparch.filter <- function( x , params ){
T   <- length(x)
if( any(!is.finite(params)) ){
filter = list( loglik=-Inf , sigma2=rep(NA,T) )
return( filter )
}
result <- .C( 'aparch_filter',
status = as.integer(0),
sigma2 = as.double(rep(0,T)) ,
eps    = as.double(rep(0,T)) ,
loglik = as.double(0) ,
as.double(params) ,
as.double(x) ,
as.integer(T)
)
return(list( loglik=result$loglik , sigma2=result$sigma2 ))
}
llh <- function(params){
filter <- aparch.filter(Tx,params)
return(-filter$loglik)
}
Hessian <- function(par){
epsilon = 0.00001  * par
npar=length(par)
hess = matrix(0, ncol = npar, nrow = npar)
for (i in 1:npar) {
for (j in 1:npar) {
x1 = x2 = x3 = x4  = par
x1[i] = x1[i] + epsilon[i]; x1[j] = x1[j] + epsilon[j]
x2[i] = x2[i] + epsilon[i]; x2[j] = x2[j] - epsilon[j]
x3[i] = x3[i] - epsilon[i]; x3[j] = x3[j] + epsilon[j]
x4[i] = x4[i] - epsilon[i]; x4[j] = x4[j] - epsilon[j]
hess[i, j] = (llh_hessian(x1)-llh_hessian(x2)-llh_hessian(x3)+llh_hessian(x4))/
(4*epsilon[i]*epsilon[j])
}
}
return(hess)
}
APARCH.fit <- function(x){
# Initialise parameters and set bounds
Tx <<- x
Meanx = mean(Tx); Varx = var(Tx); S = 1e-6
params_init = c(mu = Meanx, omega = 0.1*Varx, alpha = 0.1, gam1= 0.02, beta = 0.81,delta=2)
lowerBounds = c(mu = -10*abs(Meanx), omega = S^2, alpha = S, gam1= -(1-S), beta = S,delta=0.1)
upperBounds = c(mu = 10*abs(Meanx), omega = 10*Varx, alpha = 1-S, gam1 = (1-S), beta = 1-S,delta=5)
# Optimise -log-likelihood and calculate Hessian matrix
fit = nlminb(start = params_init, objective = llh,
lower = lowerBounds, upper = upperBounds) # , control = list(trace=3))
hess <- Hessian(fit$par)
cat("Log likelihood at MLEs: ","\n")
print(-llh(fit$par))
# Step 6: Create and Print Summary Report:
se.coef = sqrt(abs(diag(solve(hess))))
tval = fit$par/se.coef
matcoef = cbind(fit$par, se.coef, tval, 2*(1-pnorm(abs(tval))))
dimnames(matcoef) = list(names(tval), c(" Estimate", " Std. Error", " t value", "Pr(>|t|)"))
cat("\nCoefficient(s):\n")
printCoefmat(matcoef, digits = 6, signif.stars = TRUE)
# compute output
est=fit$par
mu = est[1]; omega = est[2]; alpha = est[3]; gam1=est[4]; beta = est[5]; delta = est[6]
z= Tx-mu
sigma.t = aparch.filter(x,est)$sigma2
return(list(summary = matcoef, residuals = z, volatility = sigma.t, par=est, n.loglik = -fit$obj))
}
ap.C <- APARCH.fit(x)
ap.R <- aparch11(x)
rm(list=ls())
setwd('/home/euan/documents/financial-econ/financial-econometrics-project/')
source('aparch.R')
dyn.load("APARCH.so")
data  <- read.csv('../data/tickers/DBB.csv')
data  <- data[seq(nrow(data),1,-1),]
price <- data$Adj.Close
x     <- ( log(price[2:length(price)]) - log(price[1:(length(price)-1)]) ) * 100
aparch.filter <- function( x , params ){
T   <- length(x)
if( any(!is.finite(params)) ){
filter = list( loglik=-Inf , sigma2=rep(NA,T) )
return( filter )
}
result <- .C( 'aparch_filter',
status = as.integer(0),
sigma2 = as.double(rep(0,T)) ,
eps    = as.double(rep(0,T)) ,
loglik = as.double(0) ,
as.double(params) ,
as.double(x) ,
as.integer(T)
)
return(list( loglik=result$loglik , sigma2=result$sigma2 ))
}
llh <- function(params){
filter <- aparch.filter(Tx,params)
return(-filter$loglik)
}
Hessian <- function(par){
epsilon = 0.00001  * par
npar=length(par)
hess = matrix(0, ncol = npar, nrow = npar)
for (i in 1:npar) {
for (j in 1:npar) {
x1 = x2 = x3 = x4  = par
x1[i] = x1[i] + epsilon[i]; x1[j] = x1[j] + epsilon[j]
x2[i] = x2[i] + epsilon[i]; x2[j] = x2[j] - epsilon[j]
x3[i] = x3[i] - epsilon[i]; x3[j] = x3[j] + epsilon[j]
x4[i] = x4[i] - epsilon[i]; x4[j] = x4[j] - epsilon[j]
hess[i, j] = (llh(x1)-llh(x2)-llh(x3)+llh(x4))/
(4*epsilon[i]*epsilon[j])
}
}
return(hess)
}
APARCH.fit <- function(x){
# Initialise parameters and set bounds
Tx <<- x
Meanx = mean(Tx); Varx = var(Tx); S = 1e-6
params_init = c(mu = Meanx, omega = 0.1*Varx, alpha = 0.1, gam1= 0.02, beta = 0.81,delta=2)
lowerBounds = c(mu = -10*abs(Meanx), omega = S^2, alpha = S, gam1= -(1-S), beta = S,delta=0.1)
upperBounds = c(mu = 10*abs(Meanx), omega = 10*Varx, alpha = 1-S, gam1 = (1-S), beta = 1-S,delta=5)
# Optimise -log-likelihood and calculate Hessian matrix
fit = nlminb(start = params_init, objective = llh,
lower = lowerBounds, upper = upperBounds) # , control = list(trace=3))
hess <- Hessian(fit$par)
cat("Log likelihood at MLEs: ","\n")
print(-llh(fit$par))
# Step 6: Create and Print Summary Report:
se.coef = sqrt(abs(diag(solve(hess))))
tval = fit$par/se.coef
matcoef = cbind(fit$par, se.coef, tval, 2*(1-pnorm(abs(tval))))
dimnames(matcoef) = list(names(tval), c(" Estimate", " Std. Error", " t value", "Pr(>|t|)"))
cat("\nCoefficient(s):\n")
printCoefmat(matcoef, digits = 6, signif.stars = TRUE)
# compute output
est=fit$par
mu = est[1]; omega = est[2]; alpha = est[3]; gam1=est[4]; beta = est[5]; delta = est[6]
z= Tx-mu
sigma.t = aparch.filter(x,est)$sigma2
return(list(summary = matcoef, residuals = z, volatility = sigma.t, par=est, n.loglik = -fit$obj))
}
ap.C <- APARCH.fit(x)
ap.R <- aparch11(x)
rm(list=ls())
setwd('/home/euan/documents/financial-econ/financial-econometrics-project/')
source('aparch.R')
dyn.load("APARCH.so")
data  <- read.csv('../data/tickers/DBB.csv')
data  <- data[seq(nrow(data),1,-1),]
price <- data$Adj.Close
x     <- ( log(price[2:length(price)]) - log(price[1:(length(price)-1)]) ) * 100
aparch.filter <- function( x , params ){
T   <- length(x)
if( any(!is.finite(params)) ){
filter = list( loglik=-Inf , sigma2=rep(NA,T) )
return( filter )
}
result <- .C( 'aparch_filter',
status = as.integer(0),
sigma2 = as.double(rep(0,T)) ,
eps    = as.double(rep(0,T)) ,
loglik = as.double(0) ,
as.double(params) ,
as.double(x) ,
as.integer(T)
)
return(list( loglik=result$loglik , sigma2=result$sigma2 ))
}
llh <- function(params){
filter <- aparch.filter(Tx,params)
return(-filter$loglik)
}
Hessian <- function(par){
epsilon = 0.00001  * par
npar=length(par)
hess = matrix(0, ncol = npar, nrow = npar)
for (i in 1:npar) {
for (j in 1:npar) {
x1 = x2 = x3 = x4  = par
x1[i] = x1[i] + epsilon[i]; x1[j] = x1[j] + epsilon[j]
x2[i] = x2[i] + epsilon[i]; x2[j] = x2[j] - epsilon[j]
x3[i] = x3[i] - epsilon[i]; x3[j] = x3[j] + epsilon[j]
x4[i] = x4[i] - epsilon[i]; x4[j] = x4[j] - epsilon[j]
hess[i, j] = (llh(x1)-llh(x2)-llh(x3)+llh(x4))/
(4*epsilon[i]*epsilon[j])
}
}
return(hess)
}
APARCH.fit <- function(x){
# Initialise parameters and set bounds
Tx <<- x
Meanx = mean(Tx); Varx = var(Tx); S = 1e-6
params_init = c(mu = Meanx, omega = 0.1*Varx, alpha = 0.1, gam1= 0.02, beta = 0.81,delta=2)
lowerBounds = c(mu = -10*abs(Meanx), omega = S^2, alpha = S, gam1= -(1-S), beta = S,delta=0.1)
upperBounds = c(mu = 10*abs(Meanx), omega = 10*Varx, alpha = 1-S, gam1 = (1-S), beta = 1-S,delta=5)
# Optimise -log-likelihood and calculate Hessian matrix
fit = nlminb(start = params_init, objective = llh,
lower = lowerBounds, upper = upperBounds) # , control = list(trace=3))
hess <- Hessian(fit$par)
cat("Log likelihood at MLEs: ","\n")
print(-llh(fit$par))
# Step 6: Create and Print Summary Report:
se.coef = sqrt(abs(diag(solve(hess))))
tval = fit$par/se.coef
matcoef = cbind(fit$par, se.coef, tval, 2*(1-pnorm(abs(tval))))
dimnames(matcoef) = list(names(tval), c(" Estimate", " Std. Error", " t value", "Pr(>|t|)"))
cat("\nCoefficient(s):\n")
printCoefmat(matcoef, digits = 6, signif.stars = TRUE)
# compute output
est=fit$par
mu = est[1]; omega = est[2]; alpha = est[3]; gam1=est[4]; beta = est[5]; delta = est[6]
z= Tx-mu
sigma.t = aparch.filter(x,est)$sigma2
return(list(summary = matcoef, residuals = z, volatility = sigma.t, par=est, n.loglik = -fit$obj))
}
ap.C <- APARCH.fit(x)
ap.R <- aparch11(x)
